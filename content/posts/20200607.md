+++
date = "2020-06-07"
title = "Recursive, Tail-Recursive, Tail-Call Optimization"
summary = "Functions in Python and Scala"
+++

This is a sequel and complement to an earlier post __Recursive, Iterative, Dynamic__, demonstrating why my discussion towards the end of the __Recursive__ section was contrived. If you haven't read that post please read it before this, because I'm being lazy and not reproducing any explanation here.

We'll be using the same motivating example, although we already have a far better solution than a recursive solution, the __Dynamic__ programming solution.

##### Recursive 
Here's the recursive Python solution we had:

```python
def steps(n):
    if n < 0:
        return 0  # Base Case 1.
    if n == 0:
        return 1  # Base Case 2.
    return steps(n - 1) + steps(n - 2) + steps(n - 3)
```

Let's force a stack overflow. If we call `steps(10000)` we'll receive a `RecursionError`. What's happened? Each call to `steps` has added an entry to the stack, but these entries aren't popped off the stack until a base case within has been reached: `steps(10000)` has entered within it `steps(9999)` within which `steps(9998)` within which `steps(9997)`, and so and so forth, and the stack has been filled up! "No more!" it cries, as the program attempts to send yet another plate-load its way.

How can we keep our recursive solution whilst not overflowing the stack?

##### Tail Recursive 

If a function returns simply a call to itself we could conceivably optimise the runtime to re-use the same stack entry: we would not be adding entries to the stack; we would not overflow the stack.

So how can we turn our solution above into this "tail-recursive" format? By use of an accumulator and an inner function:

```python
def steps(n):
    step_sizes = [1, 2, 3]
    def recSteps(progress, acc):
        if not progress:
            return acc
        nth = progress.pop()
        if nth == 0:
            return recSteps(progress, acc + 1)
        if nth < 0:
            return recSteps(progress, acc)
        progress.extend([nth - step_size for step_size in step_sizes])
        return recSteps(progress, acc)
    return recSteps([n], 0)
```

(This is similar to our __Iterative__ solution.)

In Scala we could write the following.

```scala
def steps(n: Int): Int = {
  val stepSizes = List(1, 2, 3)
  def recSteps(progress: List[Int], acc: Int): Int = progress match {
    case Nil => acc
    case 0 :: xs => recSteps(xs, acc + 1)
    case x :: xs if x < 0 => recSteps(xs, acc)
    case x :: xs => recSteps((stepSizes foldRight xs)(x - _ :: _), acc)
  }
  recSteps(List(n), 0)
}
```

So what's the difference between the above?

##### Tail-Call Optimization

Scala's compiler performs the conceivable optimization that we want. It is called "tail-call optimization". Python, on the other hand, does not have this: try calling `steps(10000)` with this new solution and you'll receive a `RecursionError` again. Not many language implementations do. It's a wonderful thing to have available.

But.

The __Dynamic__ programming solution is, in this particular situation, the most suitable. What's the runtime of these recursive solutions? It's nasty. Like **O(3^n)** kinda nasty. Best avoided.
